{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exercise is to train you in debugging networks using the good old print function and also tensorboard. To simulate poor training, we will train a multilayer perceptron using the CIFAR data.\n",
    "\n",
    "1. Use the CIFAR data set reader from the first homework and read the CIFAR-10 files again. \n",
    "2. Apply random noise to the image \n",
    "3. Convert the image to float and scale to [0.0, 1.0] by dividing the pixel values by the highest pixel value.\n",
    "4. Convert all labels to onehot encoding\n",
    "5. Build a 3-layer multilayer perceptron of size [512, 256, 128]. \n",
    "6. Create a tensorboard summary for plotting the histogram of the weights of the three layers.\n",
    "7. Also write the cost / loss at the end of each epoch to tensorboard.\n",
    "8. Train the network with learning rates of [0.1, 0.01, 0.001]. You will notice that the network will not converge well.\n",
    "9. Submit the snapshot of the histograms for the three learning rates. Describe your observations.\n",
    "\n",
    "NOTE: Please submit only ipynb files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import functools\n",
    "import random\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.interpolation import rotate, shift, zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(3457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "learningrate = 0.001\n",
    "\n",
    "nhidden1 = 512\n",
    "nhidden2 = 256 \n",
    "nhidden3 = 128\n",
    "ninput = 784\n",
    "noutput = 10\n",
    "\n",
    "noofepochs = 100\n",
    "batch_size = 128\n",
    "number_images_batch = 10000\n",
    "image_shape = (32, 32, 3,)\n",
    "image_size = functools.reduce(operator.mul, image_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar-10-batches-py\\data_batch_1\n",
      "(10000, 3072)\n",
      "cifar-10-batches-py\\data_batch_2\n",
      "(10000, 3072)\n",
      "cifar-10-batches-py\\data_batch_3\n",
      "(10000, 3072)\n",
      "cifar-10-batches-py\\data_batch_4\n",
      "(10000, 3072)\n",
      "cifar-10-batches-py\\data_batch_5\n",
      "(10000, 3072)\n",
      "(50000, 3072) <class 'list'>\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "# Read all data\n",
    "alldata = np.zeros((5*number_images_batch, image_size), dtype=np.int)\n",
    "alllabels = []\n",
    "begin = 0\n",
    "end = number_images_batch\n",
    "for filename in glob.glob(os.path.join(\"cifar-10-batches-py\", \"data_batch*\")):\n",
    "    print(filename)\n",
    "    d1 = unpickle(filename)\n",
    "    labels = d1[b'labels']\n",
    "    data = d1[b'data']\n",
    "    print(data.shape)\n",
    "    alldata[begin:end,:] = data\n",
    "    alllabels.extend(labels)\n",
    "    begin = end\n",
    "    end = end+number_images_batch\n",
    "alldata = alldata.astype(np.uint8)\n",
    "print(alldata.shape, type(alllabels))\n",
    "print(len(alllabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode labels for all data\n",
    "alllabels = np.array(alllabels)\n",
    "alllabels_onehot = np.eye(noutput)[alllabels]\n",
    "print(alllabels_onehot[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randnoise(data):\n",
    "    # Add random noise from a Gaussian distribution with a mean of zero\n",
    "    # and stdev of 2. \n",
    "    noise = np.random.normal(0, 3, data.size).reshape([-1, 3072])\n",
    "    data = data+noise\n",
    "    return data\n",
    "#randnoise(alldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 3072) (128, 10) [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.] 0.0 1.0\n",
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xd46c198>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd3b0198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getbatch(alldata, alllabels, batch_size = 16):\n",
    "    nlabels = alllabels.shape[0]\n",
    "    number_of_batches = nlabels//batch_size # change to nlabels\n",
    "    for batch_number in range(number_of_batches):\n",
    "        rand_index = np.array([random.randrange(0, nlabels) for i in range(batch_size)])        \n",
    "        batch_x = alldata[rand_index]\n",
    "        batch_x = randnoise(batch_x)\n",
    "        batch_x = (batch_x-batch_x.min())/(batch_x.max()-batch_x.min())\n",
    "        batch_y = alllabels[rand_index]\n",
    "        yield (batch_x, batch_y)\n",
    "    \n",
    "a = getbatch(alldata, alllabels_onehot, batch_size = batch_size)\n",
    "x, y = next(a)\n",
    "print(x.shape, y.shape, y[5], x.min(), x.max())\n",
    "oneimage = x[5].reshape(3, 32, 32).transpose(1, 2, 0)\n",
    "print(oneimage.shape)\n",
    "plt.imshow(oneimage)\n",
    "#for x, y in getbatch(alldata, alllabels, batch_size = batch_size):\n",
    "#    print(x.shape, y.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, image_size])\n",
    "Y = tf.placeholder(tf.float32, [None, noutput])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \\\n",
    "{\n",
    "    'h1': tf.Variable(tf.random_normal([image_size, nhidden1])),\n",
    "    'h2': tf.Variable(tf.random_normal([nhidden1, nhidden2])),\n",
    "    'h3': tf.Variable(tf.random_normal([nhidden2, nhidden3])),\n",
    "    'out': tf.Variable(tf.random_normal([nhidden3, noutput]))\n",
    "}\n",
    "\n",
    "biases = \\\n",
    "{\n",
    "    'b1': tf.Variable(tf.random_normal([nhidden1])),\n",
    "    'b2': tf.Variable(tf.random_normal([nhidden2])),\n",
    "    'b3': tf.Variable(tf.random_normal([nhidden3])),\n",
    "    'out': tf.Variable(tf.random_normal([noutput]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiperceptron(x):\n",
    "    l1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['h1']), biases['b1']))\n",
    "    l2 = tf.nn.sigmoid(tf.add(tf.matmul(l1, weights['h2']), biases['b2']))\n",
    "    l3 = tf.nn.sigmoid(tf.add(tf.matmul(l2, weights['h3']), biases['b3']))\n",
    "    outl = tf.add(tf.matmul(l3, weights['out']), biases['out'])\n",
    "    return outl\n",
    "    \n",
    "model = multiperceptron(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learningrate)\n",
    "train_min = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Add to tensorboard summary\n",
    "tf.summary.histogram(\"weight_1\",weights['h1'])\n",
    "tf.summary.histogram(\"weight_2\",weights['h2'])\n",
    "tf.summary.histogram(\"weight_3\",weights['h3'])\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "filename=\"./summary_log_cifar/run\"+datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "writer = tf.summary.FileWriter(filename, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 1.9344, Accuracy: 0.2812\n",
      "Training Loss: 1.9209, Accuracy: 0.3125\n",
      "Training Loss: 1.9182, Accuracy: 0.3672\n",
      "Training Loss: 1.8662, Accuracy: 0.3594\n",
      "Training Loss: 1.6807, Accuracy: 0.4297\n",
      "Training Loss: 1.7593, Accuracy: 0.3359\n",
      "Training Loss: 1.8142, Accuracy: 0.3516\n",
      "Training Loss: 1.7546, Accuracy: 0.3438\n",
      "Training Loss: 1.8746, Accuracy: 0.3125\n",
      "Training Loss: 1.7621, Accuracy: 0.3906\n",
      "Training Loss: 1.6855, Accuracy: 0.3828\n",
      "Training Loss: 1.7816, Accuracy: 0.3672\n",
      "Training Loss: 1.6393, Accuracy: 0.3672\n",
      "Training Loss: 1.6346, Accuracy: 0.4609\n",
      "Training Loss: 1.7891, Accuracy: 0.3281\n",
      "Training Loss: 1.5149, Accuracy: 0.4141\n",
      "Training Loss: 1.4936, Accuracy: 0.4531\n",
      "Training Loss: 1.4129, Accuracy: 0.4688\n",
      "Training Loss: 1.6057, Accuracy: 0.4219\n",
      "Training Loss: 1.6707, Accuracy: 0.4062\n",
      "Training Loss: 1.4638, Accuracy: 0.4766\n",
      "Training Loss: 1.6651, Accuracy: 0.4297\n",
      "Training Loss: 1.6532, Accuracy: 0.3984\n",
      "Training Loss: 1.4968, Accuracy: 0.4453\n",
      "Training Loss: 1.4572, Accuracy: 0.4531\n",
      "Training Loss: 1.4987, Accuracy: 0.4844\n",
      "Training Loss: 1.4826, Accuracy: 0.4453\n",
      "Training Loss: 1.6297, Accuracy: 0.3984\n",
      "Training Loss: 1.3812, Accuracy: 0.5156\n",
      "Training Loss: 1.2479, Accuracy: 0.6016\n",
      "Training Loss: 1.4180, Accuracy: 0.4844\n",
      "Training Loss: 1.4337, Accuracy: 0.4688\n",
      "Training Loss: 1.4569, Accuracy: 0.4688\n",
      "Training Loss: 1.4658, Accuracy: 0.4297\n",
      "Training Loss: 1.6445, Accuracy: 0.4297\n",
      "Training Loss: 1.3979, Accuracy: 0.5078\n",
      "Training Loss: 1.3175, Accuracy: 0.5547\n",
      "Training Loss: 1.4244, Accuracy: 0.4688\n",
      "Training Loss: 1.5501, Accuracy: 0.4453\n",
      "Training Loss: 1.4132, Accuracy: 0.4375\n",
      "Training Loss: 1.5222, Accuracy: 0.4688\n",
      "Training Loss: 1.4233, Accuracy: 0.4375\n",
      "Training Loss: 1.2727, Accuracy: 0.4766\n",
      "Training Loss: 1.3489, Accuracy: 0.5469\n",
      "Training Loss: 1.4062, Accuracy: 0.4766\n",
      "Training Loss: 1.4532, Accuracy: 0.4609\n",
      "Training Loss: 1.3103, Accuracy: 0.5469\n",
      "Training Loss: 1.3769, Accuracy: 0.4766\n",
      "Training Loss: 1.3457, Accuracy: 0.5625\n",
      "Training Loss: 1.4891, Accuracy: 0.4844\n",
      "Training Loss: 1.3321, Accuracy: 0.5312\n",
      "Training Loss: 1.3326, Accuracy: 0.4844\n",
      "Training Loss: 1.2329, Accuracy: 0.5547\n",
      "Training Loss: 1.2451, Accuracy: 0.5781\n",
      "Training Loss: 1.3561, Accuracy: 0.5234\n",
      "Training Loss: 1.3223, Accuracy: 0.5391\n",
      "Training Loss: 1.2325, Accuracy: 0.5625\n",
      "Training Loss: 1.5145, Accuracy: 0.4375\n",
      "Training Loss: 1.1424, Accuracy: 0.5703\n",
      "Training Loss: 1.1634, Accuracy: 0.6406\n",
      "Training Loss: 1.3913, Accuracy: 0.5312\n",
      "Training Loss: 1.2017, Accuracy: 0.5391\n",
      "Training Loss: 1.1816, Accuracy: 0.5859\n",
      "Training Loss: 1.1913, Accuracy: 0.5234\n",
      "Training Loss: 1.0560, Accuracy: 0.6172\n",
      "Training Loss: 1.2124, Accuracy: 0.5547\n",
      "Training Loss: 1.1100, Accuracy: 0.5781\n",
      "Training Loss: 1.1850, Accuracy: 0.5625\n",
      "Training Loss: 1.2186, Accuracy: 0.5547\n",
      "Training Loss: 1.2590, Accuracy: 0.5156\n",
      "Training Loss: 1.1516, Accuracy: 0.5391\n",
      "Training Loss: 1.1387, Accuracy: 0.6172\n",
      "Training Loss: 0.9874, Accuracy: 0.6797\n",
      "Training Loss: 1.2283, Accuracy: 0.5625\n",
      "Training Loss: 1.2552, Accuracy: 0.5469\n",
      "Training Loss: 1.1520, Accuracy: 0.6719\n",
      "Training Loss: 1.0232, Accuracy: 0.6641\n",
      "Training Loss: 0.9628, Accuracy: 0.6719\n",
      "Training Loss: 1.1665, Accuracy: 0.5625\n",
      "Training Loss: 0.9576, Accuracy: 0.6172\n",
      "Training Loss: 1.1329, Accuracy: 0.6328\n",
      "Training Loss: 1.2978, Accuracy: 0.5391\n",
      "Training Loss: 1.0176, Accuracy: 0.6406\n",
      "Training Loss: 1.0757, Accuracy: 0.6328\n",
      "Training Loss: 0.9957, Accuracy: 0.6719\n",
      "Training Loss: 1.1761, Accuracy: 0.6172\n",
      "Training Loss: 1.0144, Accuracy: 0.6484\n",
      "Training Loss: 1.1088, Accuracy: 0.5859\n",
      "Training Loss: 1.1509, Accuracy: 0.5938\n",
      "Training Loss: 1.1556, Accuracy: 0.5938\n",
      "Training Loss: 1.0072, Accuracy: 0.6719\n",
      "Training Loss: 0.9375, Accuracy: 0.6562\n",
      "Training Loss: 1.1369, Accuracy: 0.6250\n",
      "Training Loss: 0.9785, Accuracy: 0.6484\n",
      "Training Loss: 1.0852, Accuracy: 0.5703\n",
      "Training Loss: 0.8784, Accuracy: 0.7266\n",
      "Training Loss: 0.9992, Accuracy: 0.6094\n",
      "Training Loss: 1.0851, Accuracy: 0.6094\n",
      "Training Loss: 1.1293, Accuracy: 0.5938\n",
      "Training Loss: 0.8536, Accuracy: 0.6641\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)    \n",
    "        \n",
    "    for epoch in range(noofepochs):\n",
    "        #count = 0\n",
    "        for batch_x, batch_y in getbatch(alldata, alllabels_onehot, batch_size = batch_size):            \n",
    "            sess.run(train_min, feed_dict={X:batch_x,Y:batch_y})\n",
    "\n",
    "        losscalc, accuracycalc, merged_summary = \\\n",
    "                      sess.run([loss, accuracy, merged_summary_op], feed_dict={X:batch_x, Y:batch_y})\n",
    "        print(\"Training Loss: %0.4f, Accuracy: %0.4f\"%(losscalc, accuracycalc))\n",
    "        writer.add_summary(merged_summary, epoch)\n",
    "        \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss:\n",
    "In the figure below, you will notice that the loss does not decrease as fast as it did for MNIST data set. The accuracy (66%) is very low compared to the accuracy for MNIST data set (95%+)\n",
    "\n",
    "<img src=\"results/loss_mnist.png\" height=\"200px\">\n",
    "\n",
    "### Weights: \n",
    "If you compare the various weights, you will see that the histogram of weight1 has barely changed while weight3 underwent some change. Due to vanishing gradient in sigmoid function, the gradient flowing from weight3 reduces significantly by the time it reaches weight1. Hence the weight update will be smaller in weight1 resulting in imperceptible change to histogram. Thus, weight3 has learnt in the training while weight1 has barely learnt anything beyond its initial value.\n",
    "\n",
    "\n",
    "<img src=\"results/weight1_cifar.png\" height=\"200px\">\n",
    "<img src=\"results/weight2_cifar.png\" height=\"200px\">\n",
    "<img src=\"results/weight3_cifar.png\" height=\"200px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nteract": {
   "version": "0.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
